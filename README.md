<img src="https://github.com/jonchia/ANZ-Data-Task2/blob/main/Screenshot/Data%40ANZ%20Program.png" width ="300" height="150">

# ANZ@Data
This is a virtual internship opportunity provided by Forage. There are two tasks that are provided in this virtual internship. This repository will only discuss and highlight Task 2. 

Task 2 includes the activity to explore correlations between customer attirbutes, build a regression and a decision-tree prediction model based on findings.

# Files & Data 
**Code script file:** There is only one code script file, which is as follows:
* **Task_2.ipynb** - For analysing making predictive analytics

**Data:** There are two sets of datasets used, which are as follows:
* The [dataset](https://github.com/jonchia/ANZ-Data/blob/main/Data/ANZ%20synthesised%20transaction%20dataset.xlsx) provided contains 3 months worth of transactions for 100 hypothethical customers. It contains purchases, recurring transactions, and salary transactions.

# Launch
## Technologies

* **Python** - Python programming language is utilized as a standalone base to solve the purpose of the project.
* **Jupyter Notebook** - Jupyter is utilized as a platform to write code scripts in Python and do the data pre-processing and visualization.
* **Pandas** - Pandas library in Python is put to use for data manipulation and analysis.
* **NumPy** - NumPy library of python is used for statistical purposes
* **scikit-learn** - Machine learning library for Python


## Setup
To run the code script pelase follow the steps below:
1. Install Anaconda (64-bit graphical installer version, if not previously installed), it can be installed via https://www.anaconda.com/products/individual
2. Launch the Jupyter Notebook from the Anaconda navigator page or it can be directly launched from the terminal if Anaconda is previously installed.
3. Download the code script for this GitHub repository and save it in your working directory of Jupyter notebook. Alternatively, the code script can be uploaded directly in the Jupyter Notebook.
4. The required datasets also needs to be uploaded in the current working directory of Jupyter.
5. Install the required libraries if not previously installed.
6. Import the list of libraries.
7. Run the script!



